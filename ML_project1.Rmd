---
title: "Predicting Cardiovascular disease and its risk factor using machine learning algorithms"
author: "Varun Putta, Zhiyi Ying, Hang Lei"
date: "2024-04-27"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Install and load all important libraries
suppressMessages(install.packages("tidymodels", repos = "http://cran-us.project.com", quietly = TRUE))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))
suppressMessages(library(tidymodels))
suppressMessages(library(readr))
suppressMessages(library(ISLR))
suppressMessages(library(tidyverse))   
suppressMessages(library(caret))       
suppressMessages(library(rpart))  
suppressMessages(library(rpart.plot)) 
suppressMessages(library(ROCR))        
```

Our Research Question is :
How can a novel machine learning model, integrating socio-economic indicators, environmental factors, and traditional risk factors, enhance the accuracy of predicting cardiovascular disease risk compared to existing models primarily reliant on traditional risk factors? 

Outcome Varibale : Heart Disease

Data Preparation

One essential part of this project is to import and clean the data as needed. 
According to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.
This dataset is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relavant information about the patient.

The data is originally taken from kaggel: https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset/data

I. Importing data and creating the Dataframe
Setting up the working directory; ‘CVD Detection data.csv’ Dataset has already been downloaded from kaggle

```{r}
CVD <- CVD <- read.csv("/Users/varun/Desktop/Machine learning project/CVD Detection data.csv")
```

II. Examining the DataFrame
```{r}
head(CVD)
str(CVD)
```

The dataset contains 5110 rows of 12 variables. The variables in the dataframe are
gender, age, hypertension, heart disease, ever married, work type, residence type
avg glucose level, bmi, smoking status, stroke

III. Create Tidy Data :

The raw data has been loaded, now we need to pre-process it in order to get the data into a tidy format. To begin with, we need to find if there are any missing values and duplicate columns or rows.

```{r}
  

# Check for missing values
missing_values <- colSums(is.na(CVD))


# Print the number of missing values for each column
print(missing_values)

#There are no missing values 

# Check for duplicate rows
duplicate_rows <- CVD[duplicated(CVD), ]

# Print duplicate rows
print(duplicate_rows)
#No dupilcate rows


# Convert 'bmi' to numeric, replacing 'N/A' with NA
CVD$bmi <- as.numeric(ifelse(CVD$bmi == "N/A", NA, CVD$bmi))
# Handle missing values in 'bmi' by imputing with median
CVD$bmi[is.na(CVD$bmi)] <- median(CVD$bmi, na.rm = TRUE)

# Encode categorical variables using dummy variables (one-hot encoding)
CVD <- CVD %>% mutate(gender_male = as.integer(gender == "Male"),
         ever_married_yes = as.integer(ever_married == "Yes"),
         work_type_private = as.integer(work_type == "Private"),
         residence_type_urban = as.integer(Residence_type == "Urban"),
         smoking_status_formerly_smoked = as.integer(smoking_status == "formerly smoked"),
         smoking_status_never_smoked = as.integer(smoking_status == "never smoked"),
         smoking_status_smokes = as.integer(smoking_status == "smokes"))

# Remove the original categorical variables
CVD <- select(CVD, -gender, -ever_married, -work_type, -Residence_type, -smoking_status)

# Print the pre-processed dataset
head(CVD)
```
There are no missing values, duplicate rows in the dataset

Exploratory Data Analysis: 

```{r}
# Summary statistics
summary(CVD)

# Distribution of heart disease
ggplot(CVD, aes(x = factor(heart_disease))) +
  geom_bar(fill = "skyblue", color = "black", width = 0.5) +
  labs(title = "Distribution of Heart Disease",
       x = "Heart Disease",
       y = "Count")

# Gender distribution
ggplot(CVD, aes(x = factor(gender_male), fill = factor(heart_disease))) +
  geom_bar(position = "dodge") +
  labs(title = "Gender Distribution by Heart Disease",
       x = "Gender",
       y = "Count",
       fill = "Heart Disease") +
  scale_x_discrete(labels = c("Female", "Male"))

# Age distribution by heart disease
ggplot(CVD, aes(x = age, fill = factor(heart_disease))) +
  geom_density(alpha = 0.5) +
  labs(title = "Age Distribution by Heart Disease",
       x = "Age",
       y = "Density",
       fill = "Heart Disease")

# Distribution of stroke with reduced width
ggplot(CVD, aes(x = factor(stroke))) +
  geom_bar(fill = "skyblue", color = "black", width = 0.5) +
  labs(title = "Distribution of Stroke",
       x = "Stroke",
       y = "Count") 

# Hypertension distribution
ggplot(CVD, aes(x = factor(hypertension), fill = factor(heart_disease))) +
  geom_bar(position = "dodge") +
  labs(title = "Hypertension Distribution by Heart Disease",
       x = "Hypertension",
       y = "Count",
       fill = "Heart Disease")

# Married status distribution
ggplot(CVD, aes(x = factor(ever_married_yes), fill = factor(heart_disease))) +
  geom_bar(position = "dodge") +
  labs(title = "Married Status Distribution by Heart Disease",
       x = "Ever Married",
       y = "Count",
       fill = "Heart Disease") +
  scale_x_discrete(labels = c("No", "Yes"))

# Work type distribution
ggplot(CVD, aes(x = factor(work_type_private), fill = factor(heart_disease))) +
  geom_bar(position = "dodge") +
  labs(title = "Work Type Distribution by Heart Disease",
       x = "Work Type",
       y = "Count",
       fill = "Heart Disease") +
  scale_x_discrete(labels = c("Non-Private", "Private"))


# Residence type distribution
ggplot(CVD, aes(x = factor(residence_type_urban), fill = factor(heart_disease))) +
  geom_bar(position = "dodge") +
  labs(title = "Residence Type Distribution by Heart Disease",
       x = "Residence Type",
       y = "Count",
       fill = "Heart Disease") +
  scale_x_discrete(labels = c("Rural", "Urban"))

# Average glucose level distribution by heart disease
ggplot(CVD, aes(x = avg_glucose_level, fill = factor(heart_disease))) +
  geom_density(alpha = 0.5) +
  labs(title = "Average Glucose Level Distribution by Heart Disease",
       x = "Average Glucose Level",
       y = "Density",
       fill = "Heart Disease")

# Smoking status distribution

ggplot(CVD, aes(x = factor(smoking_status_formerly_smoked), fill = factor(heart_disease))) +
  geom_bar(position = "dodge") +
  labs(title = "Smoking Status Distribution by Heart Disease",
       x = "Smoking Status",
       y = "Count",
       fill = "Heart Disease") +
  scale_x_discrete(labels = c("Not Formerly Smoked", "Formerly Smoked"))

# Stroke distribution
ggplot(CVD, aes(x = factor(stroke), fill = factor(heart_disease))) +
  geom_bar(position = "dodge") +
  labs(title = "Stroke Distribution by Heart Disease",
       x = "Stroke",
       y = "Count",
       fill = "Heart Disease")
```

Logistic Regression
```{r}
# Load necessary libraries
library(tidyverse)
library(caret)
library(e1071)

# Prepare data for modeling
set.seed(123) 
training_samples <- CVD$heart_disease %>%
  createDataPartition(p = 0.75, list = FALSE)
train_data <- CVD[training_samples, ]
test_data <- CVD[-training_samples, ]

#Over all model
# Fit logistic regression model
fit <- glm(heart_disease ~ . - id , data = train_data, family = binomial())

# Summarize the model
summary(fit)

# Predict on test data
predictions_lr <- predict(fit, test_data, type = "response")
predicted_classes <- ifelse(predictions_lr > 0.5, 1, 0)

# Confusion matrix to evaluate the model
confusionMatrix(as.factor(predicted_classes), as.factor(test_data$heart_disease))

# Plot ROC curve and calculate AUC
pred <- prediction(predictions_lr, test_data$heart_disease)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, main = "ROC Curve")
auc <- performance(pred, measure = "auc")
auc_value <- auc@y.values[[1]]
cat("AUC:", auc_value, "\n")
conf_mat1 <- confusionMatrix(as.factor(predicted_classes), as.factor(test_data$heart_disease))
cat("Logistic Model1 Evaluation Metrics:\n")
cat("Accuracy:", conf_mat1$overall['Accuracy'], "\n")
cat("Precision:", conf_mat1$byClass['Precision'], "\n")
cat("Recall:", conf_mat1$byClass['Recall'], "\n")
cat("F1 Score:", conf_mat1$byClass['F1'], "\n")





fit2 <- glm(heart_disease ~ . - id - hypertension - bmi - stroke - ever_married_yes - work_type_private - residence_type_urban - smoking_status_formerly_smoked - smoking_status_never_smoked , data = train_data, family = binomial())

# Summarize the model
summary(fit2)

# Predict on test data
predictions2 <- predict(fit2, test_data, type = "response")
predicted_classes2 <- ifelse(predictions2 > 0.5, 1, 0)

# Confusion matrix to evaluate the model
confusionMatrix(as.factor(predicted_classes2), as.factor(test_data$heart_disease))

# Plot ROC curve and calculate AUC
pred2 <- prediction(predictions2, test_data$heart_disease)
perf2 <- performance(pred2, measure = "tpr", x.measure = "fpr")
plot(perf2, main = "ROC Curve")
auc2 <- performance(pred2, measure = "auc")
auc_value2 <- auc2@y.values[[1]]
cat("AUC:", auc_value2, "\n")

conf_mat2 <- confusionMatrix(as.factor(predicted_classes2), as.factor(test_data$heart_disease))
cat("Logistic Model2 Evaluation Metrics:\n")
cat("Accuracy:", conf_mat2$overall['Accuracy'], "\n")
cat("Precision:", conf_mat2$byClass['Precision'], "\n")
cat("Recall:", conf_mat2$byClass['Recall'], "\n")
cat("F1 Score:", conf_mat2$byClass['F1'], "\n")

```

We began our analysis with logistic regression, a classical and interpretable model widely used for binary classification tasks. Leveraging the glm() function in R, we constructed a logistic regression model to predict the likelihood of heart disease based on patient features. The model exhibited a commendable accuracy of approximately 94.2%, indicating its effectiveness in distinguishing between individuals with and without heart disease. While logistic regression offers simplicity and interpretability, its linear decision boundary may limit its ability to capture complex relationships within the data.

kNN
```{r}
# Convert heart_disease to a factor with two levels
train_data$heart_disease <- factor(train_data$heart_disease, levels = c(0, 1))
test_data$heart_disease <- factor(test_data$heart_disease, levels = c(0,1))
# Train-control part
k_values <- data.frame(k = 1:100)

# Create a trainControl object for cross-validation
train_control <- trainControl(method = "cv", number = 5)

# Train the kNN model with a range of k values
kNN_model <- train(heart_disease ~ .,           # Formula: response ~ predictors
                   data = train_data,              # Training data
                   method = "knn",             # kNN algorithm
                   trControl = train_control,  # Training control
                   tuneGrid = k_values)        # Grid of values for tuning parameter



#Plot the kNN model
library(ggplot2)
# generate the predicted labels from the training data
predicted_labels <- predict(kNN_model, train_data)

# Combine the training data with the predicted labels
train_data_with_labels <- cbind(train_data, predicted_labels)

cv_results <- kNN_model$results

# Plot the training data points

ggplot(cv_results, aes(x = k, y = Accuracy)) +
  geom_line() +
  labs(title = "Root Mean Squared Error vs. Number of Neighbors (k)",
       x = "k (Number of Neighbors)",
       y = "Root Mean Squared Error")


```
# generate prediction for the test data (CVD_te) using the trained model and plot the kNN
```{r}
test_predictions <- predict(kNN_model, test_data[, !names(test_data) %in% "heart_disease"], prob = TRUE)


# Create a data frame with the actual and predicted values
predictions_df <- data.frame(Actual = test_data$heart_disease, Predicted = test_predictions)

# Use the scatterplot function to create the kNN scatterplot

ggplot(predictions_df, aes(x = Actual, y = Predicted, color = factor(Actual))) +
  geom_point() +
  labs(x = "Actual", y = "Predicted", color = "Actual Class") +
  ggtitle("kNN Scatterplot")

```
# Confusion matrix
```{r}
# Create confusion matrix
conf_matrix <- confusionMatrix(test_predictions, test_data$heart_disease)
print(conf_matrix)

# Extract and print evaluation metrics from confusion matrix
cat("Precision:", conf_matrix$byClass['Precision'], "\n")
cat("Recall (Sensitivity):", conf_matrix$byClass['Recall'], "\n")
cat("F1 Score:", conf_matrix$byClass['F1'], "\n")


```
# ROC-AUC
```{r}
test_prob_predictions <- predict(kNN_model, test_data[, !names(test_data) %in% c("heart_disease")], type = "prob")

pred <- prediction(test_prob_predictions[,2], test_data$heart_disease)

perf <- performance(pred, "tpr", "fpr")

# Caculate AUC
auc <- performance(pred, measure = "auc")
auc_value <- auc@y.values[[1]]  
cat("AUC for kNN Model:", auc_value, "\n")

# Plot ROC curve
plot(perf, main = "ROC Curve for kNN")

```

In our exploration of machine learning algorithms, we implemented the k-nearest neighbors (KNN) algorithm to predict heart disease. Utilizing the knn() function from the class package in R, we constructed a KNN model that considers the proximity of data points to make predictions. With an accuracy of approximately 94.6%, our KNN model demonstrated competitive performance in identifying individuals at risk of heart disease. However, it's important to note that KNN's computational complexity increases with larger datasets, as it necessitates computing distances to all data points.



Decision Tree
```{r}
# Load necessary libraries
library(tidyverse)
library(caret)
library(rpart)
library(rpart.plot)
library(ROCR)

# Prepare data for modeling
set.seed(123)  
training_samples <- CVD$heart_disease %>%
  createDataPartition(p = 0.75, list = FALSE)
train_data <- CVD[training_samples, ]
test_data <- CVD[-training_samples, ]

# Fit decision tree model with adjusted parameters
fit_dt <- rpart(heart_disease ~ . - id, 
                data = train_data, 
                method = "class", 
                control = rpart.control(minsplit = 20, 
                                        minbucket = 1, 
                                        cp = 0.001, 
                                        maxdepth = 5))

summary(fit_dt)
# Plot the decision tree with improved visualization
rpart.plot(fit_dt, 
           main = "Decision Tree for Heart Disease Prediction", 
           extra = 106)  # 'extra = 106' shows split labels, 'improve' percentages, and node numbers

# Predict on test data
predictions_dt <- predict(fit_dt, test_data, type = "class")
prob_predictions_dt <- predict(fit_dt, test_data, type = "prob")[,2]

# Confusion matrix to evaluate the model
confusionMatrix(predictions_dt, as.factor(test_data$heart_disease))
conf_mat_dt <- confusionMatrix(predictions_dt, as.factor(test_data$heart_disease))
cat("Decision Tree Model Evaluation Metrics:\n")
cat("Accuracy:", conf_mat_dt$overall['Accuracy'], "\n")
cat("Precision:", conf_mat_dt$byClass['Precision'], "\n")
cat("Recall:", conf_mat_dt$byClass['Recall'], "\n")
cat("F1 Score:", conf_mat_dt$byClass['F1'], "\n")

# Plot ROC curve and calculate AUC
pred_dt <- prediction(prob_predictions_dt, test_data$heart_disease)
perf_dt <- performance(pred_dt, "tpr", "fpr")
plot(perf_dt, main = "ROC Curve for Decision Tree")
auc_dt <- performance(pred_dt, "auc")
auc_value_dt <- auc_dt@y.values[[1]]
cat("AUC for Decision Tree:", auc_value_dt, "\n")

```

Moving on to decision trees, we employed the rpart package in R to construct a tree-based model for heart disease prediction. Decision trees offer an intuitive representation of decision-making processes and feature importance. Our decision tree model achieved an accuracy of around 94.2%, indicating its ability to effectively classify individuals based on their attributes. Despite its interpretability, decision trees are prone to overfitting, potentially leading to reduced generalization performance on unseen data.

Random Forrest
```{r}
# Fit Random Forest model
library(randomForest)
# Convert 'heart_disease' to factor
CVD$heart_disease <- factor(CVD$heart_disease)

# Prepare data for modeling
set.seed(123)  # for reproducibility
training_samples <- CVD$heart_disease %>%
  createDataPartition(p = 0.75, list = FALSE)
train_data <- CVD[training_samples, ]
test_data <- CVD[-training_samples, ]

# Fit Random Forest model
fit_rf <- randomForest(heart_disease ~ . - id, 
                       data = train_data, 
                       ntree = 500,  # Number of trees in the forest
                       mtry = sqrt(ncol(train_data)),  # Number of variables randomly sampled as candidates at each split
                       importance = TRUE)  # Calculate variable importance

print(fit_rf)

# Predict on test data
predictions_rf <- predict(fit_rf, test_data)

# Convert predictions to factor and ensure levels match those of the actual data
predictions_rf <- factor(predictions_rf, levels = levels(test_data$heart_disease))




# Confusion matrix to evaluate the model
confusionMatrix(predictions_rf, test_data$heart_disease)
conf_mat_rf <- confusionMatrix(predictions_rf, test_data$heart_disease)
cat("Random Forest Model Evaluation Metrics:\n")
cat("Accuracy:", conf_mat_rf$overall['Accuracy'], "\n")
cat("Precision:", conf_mat_rf$byClass['Precision'], "\n")
cat("Recall:", conf_mat_rf$byClass['Recall'], "\n")
cat("F1 Score:", conf_mat_rf$byClass['F1'], "\n")



# Plot ROC curve and calculate AUC

train_data$heart_disease <- factor(train_data$heart_disease, levels = c(0, 1))
test_data$heart_disease <- factor(test_data$heart_disease, levels = c(0,1))

prob_predictions_rf <- predict(fit_rf, test_data, type = "prob")[,2]
pred_rf <- prediction(prob_predictions_rf, test_data$heart_disease)
perf_rf <- performance(pred_rf, "tpr", "fpr")
plot(perf_rf, main = "ROC Curve for Random Forest")
auc_rf <- performance(pred_rf, "auc")
auc_value_rf <- auc_rf@y.values[[1]]
cat("AUC for Random Forest:", auc_value_rf, "\n")
```

To address the limitations of individual decision trees, we turned to random forest, an ensemble learning method that combines multiple decision trees to enhance predictive performance. Using the randomForest package in R, we constructed a random forest model for heart disease prediction. By aggregating predictions from multiple trees, our random forest model achieved an accuracy of approximately 94.6%, slightly outperforming the individual decision tree. Moreover, random forest provided insights into feature importance, facilitating a deeper understanding of the underlying factors contributing to heart disease risk.

Ensemble Method
```{r}
# Ensemble Method

predictions_df <- as.numeric(predictions_df[,2])  
predictions_rf <- as.numeric(predictions_rf)
predictions_dt <- as.numeric(predictions_dt)
predictions_lr <- as.numeric(predictions_lr)
predictions2 <- as.numeric(predictions2)

# Combine predictions
combined_predictions <- cbind(predictions_rf, predictions_df, predictions_dt, predictions_lr, predictions2)

# Calculate the mean of predictions row-wise
ensemble_predictions <- ifelse(rowMeans(combined_predictions) > 0.5, 1, 0)

# Evaluate ensemble performance
conf_mat_ensemble <- confusionMatrix(as.factor(ensemble_predictions), as.factor(test_data$heart_disease))
print(conf_mat_ensemble)

ensemble_predictions <- ifelse(rowMeans(cbind(predictions_rf, predictions_df, predictions_dt, predictions_lr, predictions2)) > 0.5, 1, 0)

# Evaluate ensemble performance

conf_mat_ensemble <- confusionMatrix(as.factor(ensemble_predictions), test_data$heart_disease)
print(conf_mat_ensemble)
```


In our project, we utilized an ensemble method to combine predictions from multiple machine learning models, including random forest, decision trees, and logistic regression. By averaging the predictions from each model, we aimed to leverage the collective knowledge of diverse algorithms to enhance predictive performance. However, our ensemble model exhibited limited effectiveness, achieving an accuracy of only around 5.4%. Challenges such as potential level mismatch between predictions and test data need to be addressed to improve the reliability of the ensemble approach. Further refinement and tuning are 
necessary to optimize the ensemble model for our task of heart disease prediction.